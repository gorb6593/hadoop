package mapred.exam.stock;

import java.io.BufferedReader;
import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class StockMapper extends Mapper<LongWritable, Text, Text, IntWritable>{

	Text outputKey = new Text();
	static final IntWritable outputval = new IntWritable(1);
	//입력데이터로 line하나가 전달되고 line하나를 어떻게 처리할 것인지 명시
	//하둡프레임워크 내부에서 전체적인 상황을 판단하고 스케줄링되어 자동으로 반복실행
	@Override
	protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, IntWritable>.Context context)
			throws IOException, InterruptedException {
		if(key.get()>0) {
			String[] line = value.toString().split(",");
			if(line!=null & line.length>0) {
				//년도별 상승마감
				//년데이터로 키 값을 셋팅 - 날짜데이터에서 4자리만 추출해서 키로 셋팅
				outputKey.set(line[2].substring(0,4));
				//상승마감을 골라 value로 셋팅
				double result = Double.parseDouble(line[6]) - Double.parseDouble(line[3]);
				
				if(result>0) {
					context.write(outputKey, outputval);
				}
			}
		}
		
		
		
		
		
		
		StringTokenizer st = new StringTokenizer(value.toString());
		while(st.hasMoreTokens()) {
			String token = st.nextToken();
			outputKey.set(token);
			context.write(outputKey, outputval);
		}
		String line = br.readLine();
		String[] data = line.split(",");
	
	}
	
}
